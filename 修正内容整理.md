# 特許データ学習エラー修正プロジェクト - 修正内容整理

## 🎯 プロジェクト概要
**問題**: Google ColabでTinySwallow-1.5B特許データ学習時に`FloatTensor→LongTensorエラー`発生  
**目標**: エラー解決とchat template形式での学習データ生成  
**結果**: ✅ 完全解決（2ペアのchat formatデータ生成成功）

---

## 📁 修正・作成ファイル一覧

### 🔧 修正したファイル

#### 1. `configs/patent_config.yaml`
**修正内容**: 成功パターン(Alpaca)に合わせた設定変更
```yaml
# 主要修正点
dtype: null → "float16"              # 最重要修正
use_unsloth: false → true            # 成功パターンに合わせる
packing: false → true                # 効率向上
dataset_num_proc: 1 → 2             # 成功パターンに合わせる
max_seq_length: 1024 → 512          # 保守的設定
max_steps: 200 → 100                # 成功パターンに合わせる
learning_rate: 0.00003 → 0.00005    # 成功パターンに合わせる
```

#### 2. `src/patent_processing/text_processor.py`
**修正内容**: XMLデータ抽出時のpatent_id問題解決
```python
# 修正箇所: create_training_dataset()メソッド内
# 1495-1520行目にclaims統合処理を追加
if claims:
    combined_claims_text = []
    for claim in claims:
        formatted_claim = f"【請求項{claim_number}】{claim_text}"
        combined_claims_text.append(formatted_claim)
    
    sections.append({
        'patent_id': patent_id,
        'section': 'claims',  # chat format用の統合セクション
        'text': '\n'.join(combined_claims_text)
    })

# Patent ID空文字対策（1487-1494行目追加）
if not patent_id or patent_id.strip() == '':
    file_name = row.get('file_name', 'unknown')
    dummy_id = f"patent_{hash(file_name) % 100000:05d}"
    patent_id = dummy_id
```

#### 3. `src/data_processing.py`
**修正内容**: JSON処理未実装問題解決
```python
# 修正箇所: process_item()メソッド（64-140行目）
elif data_path.endswith('.json') or data_path.endswith('.jsonl'):
    import json
    processed_data = []
    
    # 文字化け対策のため複数のエンコーディングを試行
    encodings = ['utf-8', 'cp932', 'shift_jis', 'utf-8-sig']
    
    for encoding in encodings:
        try:
            with open(data_path, 'r', encoding=encoding) as f:
                data = json.load(f)
            break
        except (UnicodeDecodeError, json.JSONDecodeError):
            continue
```

#### 4. `src/training_utils.py`
**修正内容**: データ型変換エラー対策
```python
# 修正箇所: SFTTrainerの設定部分
def formatting_prompts_func(examples):
    """型変換を含むデータフォーマット関数"""
    if isinstance(examples, dict):
        text = examples.get(self.config.data.text_field, "")
        return {"text": [str(text)]}
    # バッチ処理とエラーハンドリング追加
```

---

## 🆕 新規作成スクリプト

### 🧹 データクリーニング系

#### 1. `scripts/clean_patent_data.py`
**設計思想**: 異常データの除去と文字数制限
**主要機能**:
- 異常文字列除去（CHEMICAL6479, LEGAL170等）
- 文字エンコーディング対策（複数エンコーディング試行）
- 段階的データサイズ生成（小・中・大）

**主要メソッド**:
```python
class PatentDataCleaner:
    def clean_patent_text(self, text: str) -> str  # 異常パターン除去
    def limit_text_length(self, text: str, max_length: int) -> str  # 長さ制限
    def run_cleaning(self) -> None  # メイン処理
```

#### 2. `scripts/convert_to_chat_format.py`
**設計思想**: TinySwallow-1.5B-Instruct用chat template生成
**主要機能**:
- 請求項→user、実施形態→assistant形式への変換
- 特許文書特有の【】構造での区切り処理
- 定数による設定管理

**定数定義**:
```python
# コーディング規約: クラス外定数定義
CLAIMS_SECTIONS = ['claim_1', 'claim_2', 'claim_3', 'claim_4', 'claim_5', 'claims', 'claim']
EMBODIMENT_SECTIONS = ['detailed_description', 'embodiment']
MAX_CLAIMS_LENGTH = 500
MAX_EMBODIMENT_LENGTH = 800
PATENT_PARAGRAPH_PATTERN = r'【\d{4}】'  # 【0010】【0011】等
```

**主要メソッド**:
```python
class PatentChatFormatter:
    def extract_claims_and_implementations(self, data: List[Dict]) -> List[Dict]
    def preprocess_claims(self, text: str) -> str  # 【請求項N】構造対応
    def preprocess_implementation(self, text: str) -> str  # 【0010】段落対応
    def create_chat_template(self, user_message: str, assistant_message: str) -> str
```

### 🔍 検証・テスト系

#### 3. `test_patent_patterns.py`
**設計思想**: 正規表現パターンの動作検証
**主要機能**: 【請求項N】【0010】等の特許構造検出テスト

#### 4. `check_data_consistency.py`
**設計思想**: データ整合性の自動検証
**主要機能**: 請求項と実施形態の内容一致度チェック

#### 5. `check_patent_ids.py`
**設計思想**: Patent ID問題の詳細調査
**主要機能**: 空文字列patent_idの検出と統計分析

### 🛠️ 修復・統合系

#### 6. `fix_patent_ids.py`
**設計思想**: 既存データの後処理による修復
**主要機能**:
- コンテンツハッシュベースのpatent_ID生成
- セクション順序による特許境界推測
- Claims統合処理

#### 7. `test_claims_integration.py`
**設計思想**: 個別請求項から統合claimsセクション生成
**主要機能**: claim_1, claim_2... → claims統合

---

## 📋 コーディング規約・設計原則

### 🎯 命名規約
```python
# ファイル命名
check_*.py     # 検証・確認系
fix_*.py       # 修復系  
test_*.py      # テスト系
clean_*.py     # クリーニング系
convert_*.py   # 変換系

# 定数命名（全て大文字・アンダースコア区切り）
MAX_CLAIMS_LENGTH = 500
CLAIMS_SECTIONS = [...]
PATENT_MARKER_PATTERN = r'【[^】]*】'
```

### 🏗️ 設計原則

#### 1. **定数管理の一元化**
```python
# ❌ 悪い例（メソッド内定数）
def process_claims(self, text):
    max_length = 500  # メソッド内定数

# ✅ 良い例（クラス外定数）
MAX_CLAIMS_LENGTH = 500  # ファイル先頭で定義

class PatentProcessor:
    def process_claims(self, text):
        if len(text) > MAX_CLAIMS_LENGTH:
            # 処理
```

#### 2. **特許文書構造への対応**
```python
# 特許固有の構造を考慮
PATENT_PARAGRAPH_PATTERN = r'【\d{4}】'      # 【0010】段落番号
CLAIMS_PATTERN = r'【請求項\d+】'           # 【請求項1】
SECTION_PATTERN = r'【[^】\d][^】]*】'      # 【発明を実施する形態】
```

#### 3. **データ取りこぼし防止**
```python
# 文字数制限時も必ずデータを残す
if len(potential_result) <= max_length:
    result = potential_result
else:
    if result:  # 既存結果がある場合はそれを使用
        break
    else:       # 結果が空の場合は強制的にでも含める
        result = potential_block[:max_length-3] + '...'
        break

# 最終安全策
if not result:
    result = text[:max_length-3] + '...'
```

#### 4. **エラーハンドリング強化**
```python
# 複数エンコーディング試行
encodings = ['utf-8', 'cp932', 'shift_jis', 'utf-8-sig']
for encoding in encodings:
    try:
        with open(file_path, 'r', encoding=encoding) as f:
            data = json.load(f)
        break
    except (UnicodeDecodeError, json.JSONDecodeError):
        continue
```

#### 5. **統計情報とログ強化**
```python
# 処理統計の詳細出力
skipped_stats = {
    'no_claims': 0,
    'no_implementation': 0, 
    'too_short': 0,
    'success': 0
}

# デバッグ用詳細ログ
logger.debug(f"請求項前処理: {len(text)} → {len(result)} 文字")
```

---

## 🎉 成果と解決された問題

### ✅ 技術的解決事項
1. **FloatTensor→LongTensorエラー**: `dtype: "float16"`で完全解決
2. **JSON処理未実装**: 文字エンコーディング対策で解決
3. **Claims分離問題**: 統合処理で解決  
4. **Patent ID空文字**: ダミーID生成で解決
5. **Chat Template生成**: TinySwallow形式で正常動作

### 📊 最終結果
- **入力データ**: 200件 → **2つの特許**に正しく分離
- **生成ペア**: **2件**（エラー0件）
- **Chat Format**: 正常生成
- **Google Colab**: 学習準備完了

### 🎯 学習した設計パターン
1. **段階的問題解決**: データ→設定→処理の順序で修正
2. **後方互換性維持**: 既存データを破壊せず拡張
3. **防御的プログラミング**: 複数の安全策でデータ損失防止
4. **特許ドメイン対応**: 業界特有の構造への適応

これらの修正により、元の`FloatTensor→LongTensorエラー`は完全に解決され、Google Colabでの学習が可能になりました。