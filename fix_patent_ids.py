#!/usr/bin/env python3
"""
æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®patent_idã‚’ä¿®æ­£ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
import re
from pathlib import Path
from collections import defaultdict

def fix_patent_ids():
    """ç©ºã®patent_idã‚’ä¿®æ­£ã—ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªIDã‚’å‰²ã‚Šå½“ã¦"""
    
    print("ğŸ› ï¸ Patent IDä¿®æ­£å‡¦ç†")
    print("=" * 50)
    
    # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    input_path = Path("data/cleaned/cleaned_patents_medium.json")
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"ğŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿æ•°: {len(data)}")
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ã§patent_idã‚’ç”Ÿæˆ
    content_groups = defaultdict(list)
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦patentå¢ƒç•Œã‚’æ¨æ¸¬
    current_patent = []
    patent_groups = []
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é †åºã§patentå¢ƒç•Œã‚’æ¨æ¸¬
    section_order = ['abstract', 'technical_field', 'background_art', 'detailed_description', 'title']
    
    for i, item in enumerate(data):
        section = item.get('section', '')
        
        # æ–°ã—ã„ç‰¹è¨±ã®é–‹å§‹ã‚’æ¤œå‡ºï¼ˆabstractã¾ãŸã¯titleã‹ã‚‰å§‹ã¾ã‚‹ï¼‰
        if section in ['abstract', 'title'] and current_patent:
            # å‰ã®ç‰¹è¨±ã‚’ä¿å­˜
            patent_groups.append(current_patent)
            current_patent = []
        
        current_patent.append(item)
    
    # æœ€å¾Œã®ç‰¹è¨±ã‚‚è¿½åŠ 
    if current_patent:
        patent_groups.append(current_patent)
    
    print(f"ğŸ“‹ æ¨æ¸¬ã•ã‚ŒãŸç‰¹è¨±æ•°: {len(patent_groups)}")
    
    # å„ã‚°ãƒ«ãƒ¼ãƒ—ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªpatent_idã‚’å‰²ã‚Šå½“ã¦
    fixed_data = []
    
    for group_idx, patent_group in enumerate(patent_groups):
        # ç‰¹è¨±IDã‚’ç”Ÿæˆï¼ˆå†…å®¹ã®ãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ï¼‰
        content_hash = ""
        for item in patent_group:
            text = item.get('text', '')
            content_hash += text[:100]  # æœ€åˆã®100æ–‡å­—ã‚’ä½¿ç”¨
        
        # ãƒãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ¦ãƒ‹ãƒ¼ã‚¯IDã‚’ç”Ÿæˆ
        patent_id = f"JP{abs(hash(content_hash)) % 1000000:06d}"
        
        print(f"ğŸ”§ ã‚°ãƒ«ãƒ¼ãƒ— {group_idx+1}: {len(patent_group)}ã‚»ã‚¯ã‚·ãƒ§ãƒ³ â†’ {patent_id}")
        
        # å„ã‚¢ã‚¤ãƒ†ãƒ ã«patent_idã‚’è¨­å®š
        for item in patent_group:
            item['patent_id'] = patent_id
            fixed_data.append(item)
    
    # ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    output_path = Path("data/cleaned/fixed_patents_medium.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(fixed_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {output_path}")
    
    # çµ±è¨ˆè¡¨ç¤º
    patent_count = {}
    for item in fixed_data:
        pid = item['patent_id']
        patent_count[pid] = patent_count.get(pid, 0) + 1
    
    print(f"\nğŸ“ˆ ä¿®æ­£å¾Œçµ±è¨ˆ:")
    print(f"  - ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(fixed_data)}")
    print(f"  - ãƒ¦ãƒ‹ãƒ¼ã‚¯patent_idæ•°: {len(patent_count)}")
    print(f"  - å¹³å‡ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°/ç‰¹è¨±: {len(fixed_data) / len(patent_count):.1f}")
    
    print(f"\nğŸ” Patent IDåˆ†å¸ƒ:")
    for pid, count in list(patent_count.items())[:5]:
        print(f"  {pid}: {count}ã‚»ã‚¯ã‚·ãƒ§ãƒ³")
    
    return output_path

def create_enhanced_data_with_claims():
    """ä¿®æ­£ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰claimsçµ±åˆç‰ˆã‚’ä½œæˆ"""
    
    print(f"\nğŸš€ Claimsçµ±åˆç‰ˆä½œæˆ")
    print("=" * 50)
    
    # ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    fixed_path = Path("data/cleaned/fixed_patents_medium.json")
    with open(fixed_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # patent_idã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    patents_by_id = {}
    for item in data:
        patent_id = item['patent_id']
        if patent_id not in patents_by_id:
            patents_by_id[patent_id] = []
        patents_by_id[patent_id].append(item)
    
    # çµ±åˆclaimsã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
    enhanced_data = list(data)  # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
    
    for patent_id, sections in patents_by_id.items():
        # è«‹æ±‚é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³(claim_N)ã‚’æ¤œç´¢
        claim_sections = []
        for section in sections:
            section_name = section.get('section', '')
            if section_name.startswith('claim_'):
                # claimç•ªå·ã‚’æŠ½å‡º
                claim_match = re.match(r'claim_(\d+)', section_name)
                if claim_match:
                    claim_number = claim_match.group(1)
                    claim_text = section.get('text', '')
                    if claim_text:
                        claim_sections.append({
                            'number': claim_number,
                            'text': claim_text
                        })
        
        # è«‹æ±‚é …ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€çµ±åˆclaimsã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
        if claim_sections:
            # ç•ªå·é †ã«ã‚½ãƒ¼ãƒˆ
            claim_sections.sort(key=lambda x: int(x['number']))
            
            # ã€è«‹æ±‚é …Nã€‘å½¢å¼ã§çµ±åˆ
            combined_claims = []
            for claim in claim_sections:
                formatted_claim = f"ã€è«‹æ±‚é …{claim['number']}ã€‘{claim['text']}"
                combined_claims.append(formatted_claim)
            
            # çµ±åˆclaimsã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
            integrated_claims = {
                'patent_id': patent_id,
                'section': 'claims',
                'text': '\n'.join(combined_claims)
            }
            enhanced_data.append(integrated_claims)
            
            print(f"âœ… {patent_id}: {len(claim_sections)}å€‹ã®è«‹æ±‚é …ã‚’çµ±åˆ")
    
    # æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    enhanced_path = Path("data/cleaned/fixed_enhanced_patents_medium.json")
    with open(enhanced_path, 'w', encoding='utf-8') as f:
        json.dump(enhanced_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {enhanced_path}")
    print(f"ğŸ“Š æ‹¡å¼µãƒ‡ãƒ¼ã‚¿æ•°: {len(enhanced_data)}")
    
    return enhanced_path

if __name__ == "__main__":
    # Step 1: Patent IDä¿®æ­£
    fixed_path = fix_patent_ids()
    
    # Step 2: Claimsçµ±åˆ
    enhanced_path = create_enhanced_data_with_claims()
    
    print(f"\nâœ… ä¿®æ­£å®Œäº†ï¼")
    print(f"  ä¿®æ­£ãƒ‡ãƒ¼ã‚¿: {fixed_path}")
    print(f"  æ‹¡å¼µãƒ‡ãƒ¼ã‚¿: {enhanced_path}")