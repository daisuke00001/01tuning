#!/usr/bin/env python3
"""
ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
import os
from pathlib import Path

def check_cleaned_data():
    """ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‚’ç¢ºèª"""
    
    data_dir = Path("data/cleaned")
    
    print("ğŸ” ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯")
    print("=" * 50)
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
    json_files = [
        "cleaned_patents_small.json",
        "cleaned_patents_medium.json", 
        "cleaned_training_dataset.json"
    ]
    
    for filename in json_files:
        filepath = data_dir / filename
        if not filepath.exists():
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {filename}")
            continue
            
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"\nğŸ“Š {filename}:")
            print(f"  - ãƒ‡ãƒ¼ã‚¿æ•°: {len(data):,}")
            
            if len(data) > 0:
                sample = data[0]
                print(f"  - ã‚­ãƒ¼: {list(sample.keys())}")
                
                if 'text' in sample:
                    text = sample['text']
                    print(f"  - ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(text):,}")
                    print(f"  - ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {text[:150]}...")
                    
                    # ç•°å¸¸æ–‡å­—åˆ—ãƒã‚§ãƒƒã‚¯
                    abnormal_patterns = ['CHEMICAL', 'LEGAL', 'MIC', 'CHCHCHCH']
                    found_patterns = [p for p in abnormal_patterns if p in text]
                    if found_patterns:
                        print(f"  - âš ï¸ æ®‹å­˜ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³: {found_patterns}")
                    else:
                        print(f"  - âœ… ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
                file_size = filepath.stat().st_size / (1024 * 1024)
                print(f"  - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} MB")
                
        except Exception as e:
            print(f"âŒ {filename} èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nğŸ“‹ Google Colabã§ã®ä½¿ç”¨æ¨å¥¨:")
    print(f"  1. ãƒ†ã‚¹ãƒˆç”¨: cleaned_patents_small.json (50ä»¶)")
    print(f"  2. ä¸­ãƒ†ã‚¹ãƒˆç”¨: cleaned_patents_medium.json (200ä»¶)")
    print(f"  3. æœ¬æ ¼ç”¨: cleaned_training_dataset.json (436ä»¶)")
    
    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    stats_file = data_dir / "cleaning_stats.json"
    if stats_file.exists():
        with open(stats_file, 'r', encoding='utf-8') as f:
            stats = json.load(f)
        
        print(f"\nğŸ“ˆ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµ±è¨ˆ:")
        for filename, stat in stats.items():
            if 'processing_summary' in stat:
                summary = stat['processing_summary']
                print(f"  {filename}:")
                print(f"    - å…ƒãƒ‡ãƒ¼ã‚¿: {summary['original_count']}ä»¶")
                print(f"    - ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ: {summary['cleaned_count']}ä»¶")
                print(f"    - ä¿æŒç‡: {summary['retention_rate']:.1f}%")

if __name__ == "__main__":
    check_cleaned_data()