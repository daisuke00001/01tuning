#!/usr/bin/env python3
"""Option 1: æ®µè½å˜ä½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ"""

import json
import re
from pathlib import Path
from datetime import datetime

def split_into_paragraphs(text):
    """æ®µè½ç•ªå·ã€XXXXã€‘ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²"""
    if not text:
        return []
    
    # æ®µè½ç•ªå·ãƒ‘ã‚¿ãƒ¼ãƒ³ã§åˆ†å‰²
    paragraphs = re.split(r'(ã€\d{4}ã€‘)', text)
    
    result = []
    current_paragraph = None
    current_number = None
    
    for part in paragraphs:
        if re.match(r'ã€\d{4}ã€‘', part):
            # å‰ã®æ®µè½ã‚’ä¿å­˜
            if current_number and current_paragraph:
                result.append({
                    'number': current_number,
                    'content': current_paragraph.strip()
                })
            
            # æ–°ã—ã„æ®µè½ç•ªå·
            current_number = part
            current_paragraph = ""
        else:
            # æ®µè½å†…å®¹
            if current_number:
                current_paragraph += part
    
    # æœ€å¾Œã®æ®µè½ã‚’ä¿å­˜
    if current_number and current_paragraph:
        result.append({
            'number': current_number,
            'content': current_paragraph.strip()
        })
    
    return result

def create_option1_dataset(input_file, output_file, max_items=50):
    """Option 1: æ®µè½å˜ä½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ"""
    
    with open(input_file, 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    # æœ€åˆã®50ä»¶ã®ã¿å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
    original_data = original_data[:max_items]
    
    option1_data = []
    total_paragraphs = 0
    
    for item in original_data:
        patent_id = item['metadata']['patent_id']
        claims_count = item['metadata']['claims_count']
        
        # userã¨assistantãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
        user_content = None
        assistant_content = None
        
        for msg in item['messages']:
            if msg['role'] == 'user':
                user_content = msg['content']
            elif msg['role'] == 'assistant':
                assistant_content = msg['content']
        
        if not user_content or not assistant_content:
            continue
        
        # è«‹æ±‚é …éƒ¨åˆ†ã‚’æŠ½å‡º
        claims_text = user_content.replace("ä»¥ä¸‹ã®ç‰¹è¨±è«‹æ±‚ã®ç¯„å›²ã«åŸºã¥ã„ã¦ã€ç™ºæ˜ã‚’å®Ÿæ–½ã™ã‚‹ãŸã‚ã®å½¢æ…‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ï¼š\n\n", "")
        
        # assistant contentã‹ã‚‰æ®µè½ã‚’åˆ†å‰²
        # ã€ç™ºæ˜ã‚’å®Ÿæ–½ã™ã‚‹ãŸã‚ã®å½¢æ…‹ã€‘ã‚’é™¤å»
        implementation_text = assistant_content.replace("ã€ç™ºæ˜ã‚’å®Ÿæ–½ã™ã‚‹ãŸã‚ã®å½¢æ…‹ã€‘\n\n", "")
        
        paragraphs = split_into_paragraphs(implementation_text)
        
        if not paragraphs:
            continue
        
        # å„æ®µè½ã‚’å€‹åˆ¥ã®ChatMLãƒšã‚¢ã«å¤‰æ›
        for i, paragraph in enumerate(paragraphs):
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            context_info = f"ç‰¹è¨±ç•ªå·: {patent_id}"
            if i > 0:
                # å‰ã®æ®µè½ã®æƒ…å ±ã‚’å«ã‚ã‚‹
                prev_paragraphs = paragraphs[:i]
                prev_context = "\n".join([f"{p['number']}\n{p['content'][:100]}..." for p in prev_paragraphs])
                context_info += f"\n\nå‰ã®æ®µè½:\n{prev_context}"
            
            paragraph_record = {
                "messages": [
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯ç‰¹è¨±æ–‡æ›¸ã®å°‚é–€å®¶ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸç‰¹è¨±è«‹æ±‚ã®ç¯„å›²ã¨æ–‡è„ˆã«åŸºã¥ã„ã¦ã€æŒ‡å®šã•ã‚ŒãŸæ®µè½ç•ªå·ã®å®Ÿæ–½å½¢æ…‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": f"{context_info}\n\nã€è«‹æ±‚é …ã€‘\n{claims_text}\n\nä¸Šè¨˜ã«åŸºã¥ã„ã¦{paragraph['number']}ã®æ®µè½ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "assistant",
                        "content": f"{paragraph['number']}\n{paragraph['content']}"
                    }
                ],
                "metadata": {
                    "patent_id": patent_id,
                    "paragraph_number": paragraph['number'],
                    "paragraph_index": i,
                    "total_paragraphs": len(paragraphs),
                    "claims_count": claims_count,
                    "dataset_type": "option1_paragraph_unit",
                    "created_at": datetime.now().isoformat()
                }
            }
            
            option1_data.append(paragraph_record)
            total_paragraphs += 1
    
    # JSONå‡ºåŠ›
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(option1_data, f, ensure_ascii=False, indent=2)
    
    return len(option1_data), total_paragraphs

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
input_file = "/mnt/d/20250728/01tuning/data/processed/chatml_training_with_paragraphs_full.json"
output_file = "/mnt/d/20250728/01tuning/data/processed/option1_paragraph_unit.json"

print("Option 1: æ®µè½å˜ä½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ")
print("=" * 80)
print(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {Path(input_file).name}")

if not Path(input_file).exists():
    print("âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    exit(1)

dataset_count, paragraph_count = create_option1_dataset(input_file, output_file)

print(f"âœ… Option 1ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆå®Œäº†")
print(f"  å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {Path(output_file).name}")
print(f"  ç”Ÿæˆãƒ‡ãƒ¼ã‚¿æ•°: {dataset_count}ä»¶")
print(f"  ç·æ®µè½æ•°: {paragraph_count}æ®µè½")

# ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª
with open(output_file, 'r', encoding='utf-8') as f:
    sample_data = json.load(f)

if sample_data:
    first_sample = sample_data[0]
    print(f"\nğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª:")
    print(f"  ç‰¹è¨±ID: {first_sample['metadata']['patent_id']}")
    print(f"  æ®µè½ç•ªå·: {first_sample['metadata']['paragraph_number']}")
    print(f"  æ®µè½ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {first_sample['metadata']['paragraph_index']}/{first_sample['metadata']['total_paragraphs']-1}")
    
    # userã¨assistantã®å†…å®¹ã‚’è¡¨ç¤º
    for msg in first_sample['messages']:
        if msg['role'] == 'user':
            print(f"  User (æœ€åˆã®150æ–‡å­—): {msg['content'][:150]}...")
        elif msg['role'] == 'assistant':
            print(f"  Assistant: {msg['content'][:100]}...")

print(f"\nğŸ’¡ ç‰¹å¾´:")
print(f"  - å„æ®µè½ãŒç‹¬ç«‹ã—ãŸChatMLãƒšã‚¢")
print(f"  - å‰ã®æ®µè½ã®æ–‡è„ˆæƒ…å ±ã‚’å«ã‚€")
print(f"  - æ®µè½ç•ªå·ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š")
print(f"  - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ®µè½ç”Ÿæˆã«æœ€é©")