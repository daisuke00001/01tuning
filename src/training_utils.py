# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–¢é€£ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

from trl import SFTConfig, SFTTrainer
import logging
from config import Config

logger = logging.getLogger(__name__)

class TrainingManager:
    """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config: Config):
        self.config = config
        self.model = None
        self.training_stats = None
        
    def format_chatml_messages(self, example):
        """ChatMLå½¢å¼ã®messagesã‚’å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ï¼ˆãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã™ï¼‰"""
        try:
            if 'messages' in example:
                # messagesã‚’å˜ä¸€ã®ãƒ†ã‚­ã‚¹ãƒˆã«çµåˆ
                text_parts = []
                for message in example['messages']:
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å½¢å¼ã‚’ç¢ºèªã—ã¦é©åˆ‡ã«å‡¦ç†
                    if isinstance(message, dict):
                        # è¾æ›¸å½¢å¼: {"role": "user", "content": "..."}
                        role = message.get('role', '')
                        content = message.get('content', '')
                    elif isinstance(message, list) and len(message) >= 2:
                        # ãƒªã‚¹ãƒˆå½¢å¼: ["user", "content"]
                        role = str(message[0]) if message[0] else ''
                        content = str(message[1]) if message[1] else ''
                    elif isinstance(message, str):
                        # æ–‡å­—åˆ—å½¢å¼: å…¨ä½“ã‚’contentã¨ã—ã¦æ‰±ã†
                        role = 'unknown'
                        content = message
                    else:
                        # ãã®ä»–ã®å½¢å¼: æ–‡å­—åˆ—ã«å¤‰æ›
                        role = 'unknown'
                        content = str(message)
                    
                    text_parts.append(f"<|im_start|>{role}\n{content}<|im_end|>")
                
                # Unslothã¯æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã‚’æœŸå¾…ã—ã¦ã„ã‚‹ãŸã‚ã€ãƒªã‚¹ãƒˆã§è¿”ã™
                return ["\n".join(text_parts)]
            elif 'text' in example:
                # æ—¢ã«textãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹å ´åˆã¯ãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã™
                return [example['text']]
            else:
                # ã©ã¡ã‚‰ã‚‚ãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’ãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã™
                return [""]
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            logger.error(f"formatting_funcã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}, example keys: {list(example.keys()) if isinstance(example, dict) else type(example)}")
            return [str(example)]
        
    def create_trainer(self, model, tokenizer, dataset) -> SFTTrainer:
        """ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ä½œæˆ"""
        try:
            logger.info("ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’è¨­å®šä¸­...")

            # SFTConfig è¨­å®šï¼ˆå‹å¤‰æ›ã‚’ç¢ºå®Ÿã«ã™ã‚‹ï¼‰
            sft_config = SFTConfig(
                per_device_train_batch_size=int(self.config.training.per_device_train_batch_size),
                gradient_accumulation_steps=int(self.config.training.gradient_accumulation_steps),
                warmup_steps=int(self.config.training.warmup_steps),
                max_steps=int(self.config.training.max_steps),
                learning_rate=float(self.config.training.learning_rate),
                logging_steps=int(self.config.training.logging_steps),
                optim=str(self.config.training.optim),
                weight_decay=float(self.config.training.weight_decay),
                lr_scheduler_type=str(self.config.training.lr_scheduler_type),
                seed=int(self.config.training.seed),
                output_dir=str(self.config.training.output_dir),
                report_to=str(self.config.training.report_to),
            )

            # save_steps ã¨ save_total_limitãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¿½åŠ ï¼ˆå‹å¤‰æ›ä»˜ãï¼‰
            if self.config.training.save_steps is not None:
                sft_config.save_steps = int(self.config.training.save_steps)
            if self.config.training.save_total_limit is not None:
                sft_config.save_total_limit = int(self.config.training.save_total_limit)

            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å½¢å¼ã‚’ç¢ºèª
            sample_data = dataset[0] if len(dataset) > 0 else {}
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            if len(dataset) > 0:
                logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µãƒ³ãƒ—ãƒ«æ§‹é€ : {list(sample_data.keys())}")
                if 'messages' in sample_data:
                    messages = sample_data['messages']
                    logger.info(f"messagesæ§‹é€ : {type(messages)}, é•·ã•: {len(messages) if hasattr(messages, '__len__') else 'N/A'}")
                    if len(messages) > 0:
                        first_message = messages[0]
                        logger.info(f"æœ€åˆã®messageæ§‹é€ : {type(first_message)}, å†…å®¹: {first_message if len(str(first_message)) < 200 else str(first_message)[:200]+'...'}")
            
            # ChatMLå½¢å¼ã®å ´åˆã¯formatting_funcã‚’ä½¿ç”¨
            if 'messages' in sample_data:
                logger.info("ChatMLå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¤œå‡ºã€formatting_funcã‚’ä½¿ç”¨ã—ã¾ã™")
                trainer = SFTTrainer(
                    model=model,
                    tokenizer=tokenizer,
                    train_dataset=dataset,
                    formatting_func=self.format_chatml_messages,
                    max_seq_length=self.config.model.max_seq_length,
                    dataset_num_proc=self.config.data.dataset_num_proc,
                    packing=self.config.data.packing,
                    args=sft_config,
                )
            else:
                # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®å ´åˆã¯dataset_text_fieldã‚’ä½¿ç”¨
                logger.info("é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
                trainer = SFTTrainer(
                    model=model,
                    tokenizer=tokenizer,
                    train_dataset=dataset,
                    dataset_text_field=self.config.data.text_field,
                    max_seq_length=self.config.model.max_seq_length,
                    dataset_num_proc=self.config.data.dataset_num_proc,
                    packing=self.config.data.packing,
                    args=sft_config,
                )

            self.trainer = trainer
            logger.info("âœ…ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆå®Œäº†")
            return trainer
        
        except Exception as e:
            logger.error(f"âœ–ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def train(self) -> dict:
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ"""
        if self.trainer is None:
            raise ValueError("ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚create_trainer()ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        try:
            logger.info("ğŸš€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹...")

            self.training_stats = self.trainer.train()
            logger.info("âœ…ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†")
            return self.training_stats
        
        except Exception as e:
            logger.error(f"âœ–ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def get_training_summary(self) -> dict:
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        if self.training_stats is None:
            return {"error": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“"}
        
        runtime = self.training_stats.metrics.get('train_runtime', 0)

        return {
            "train_runtime_seconds": round(runtime, 1),
            "train_runtime_minutes": round(runtime / 60, 2),
            "train_samples_per_second": self.training_stats.metrics.get('train_samples_per_second', 0),
            "train_steps_per_second": self.training_stats.metrics.get('train_steps_per_second', 0),
            "total_flos": self.training_stats.metrics.get('total_flos', 0),
            "train_loss": self.training_stats.metrics.get('train_loss', 0),
        }