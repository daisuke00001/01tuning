# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–¢é€£ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

from trl import SFTConfig, SFTTrainer
import logging
from config import Config

logger = logging.getLogger(__name__)

class TrainingManager:
    """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config: Config):
        self.config = config
        self.model = None
        self.training_stats = None
        
    def format_chatml_messages(self, example):
        """ChatMLå½¢å¼ã®messagesã‚’å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ï¼ˆãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã™ï¼‰"""
        try:
            if 'messages' in example:
                # messagesã‚’å˜ä¸€ã®ãƒ†ã‚­ã‚¹ãƒˆã«çµåˆ
                text_parts = []
                for message in example['messages']:
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å½¢å¼ã‚’ç¢ºèªã—ã¦é©åˆ‡ã«å‡¦ç†
                    if isinstance(message, dict):
                        # è¾æ›¸å½¢å¼: {"role": "user", "content": "..."}
                        role = message.get('role', '')
                        content = message.get('content', '')
                    elif isinstance(message, list) and len(message) >= 2:
                        # ãƒªã‚¹ãƒˆå½¢å¼: ["user", "content"]
                        role = str(message[0]) if message[0] else ''
                        content = str(message[1]) if message[1] else ''
                    elif isinstance(message, str):
                        # æ–‡å­—åˆ—å½¢å¼: å…¨ä½“ã‚’contentã¨ã—ã¦æ‰±ã†
                        role = 'unknown'
                        content = message
                    else:
                        # ãã®ä»–ã®å½¢å¼: æ–‡å­—åˆ—ã«å¤‰æ›
                        role = 'unknown'
                        content = str(message)
                    
                    text_parts.append(f"<|im_start|>{role}\n{content}<|im_end|>")
                
                formatted_text = "\n".join(text_parts)
                
                # é•·ã•åˆ¶é™ã‚’é©ç”¨ï¼ˆãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³å•é¡Œã‚’å›é¿ï¼‰
                max_chars = self.config.model.max_seq_length * 4  # æ¦‚ç®—ã§ãƒˆãƒ¼ã‚¯ãƒ³1å€‹=4æ–‡å­—
                if len(formatted_text) > max_chars:
                    formatted_text = formatted_text[:max_chars] + "\n<|im_end|>"
                    logger.warning(f"ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹ãŸã‚åˆ‡ã‚Šè©°ã‚ã¾ã—ãŸ: {len(formatted_text)} -> {max_chars}")
                
                # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°ï¼ˆæœ€åˆã®æ•°ä»¶ã®ã¿ï¼‰
                if not hasattr(self, '_debug_count'):
                    self._debug_count = 0
                if self._debug_count < 3:
                    logger.info(f"formatted_text sample {self._debug_count}: length={len(formatted_text)}, preview={formatted_text[:200]}...")
                    self._debug_count += 1
                
                # Unslothã¯æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã‚’æœŸå¾…ã—ã¦ã„ã‚‹ãŸã‚ã€ãƒªã‚¹ãƒˆã§è¿”ã™
                return [formatted_text]
            elif 'text' in example:
                # æ—¢ã«textãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹å ´åˆã¯ãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã™
                text = example['text']
                # é•·ã•åˆ¶é™ã‚’é©ç”¨
                max_chars = self.config.model.max_seq_length * 4
                if len(text) > max_chars:
                    text = text[:max_chars]
                    logger.warning(f"ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹ãŸã‚åˆ‡ã‚Šè©°ã‚ã¾ã—ãŸ: {len(text)} -> {max_chars}")
                return [text]
            else:
                # ã©ã¡ã‚‰ã‚‚ãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’ãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã™
                return [""]
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            logger.error(f"formatting_funcã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}, example keys: {list(example.keys()) if isinstance(example, dict) else type(example)}")
            return ["[ERROR: Failed to format]"]
        
    def create_trainer(self, model, tokenizer, dataset) -> SFTTrainer:
        """ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ä½œæˆ"""
        try:
            logger.info("ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’è¨­å®šä¸­...")

            # SFTConfig è¨­å®šï¼ˆå‹å¤‰æ›ã‚’ç¢ºå®Ÿã«ã™ã‚‹ï¼‰
            sft_config = SFTConfig(
                per_device_train_batch_size=int(self.config.training.per_device_train_batch_size),
                gradient_accumulation_steps=int(self.config.training.gradient_accumulation_steps),
                warmup_steps=int(self.config.training.warmup_steps),
                max_steps=int(self.config.training.max_steps),
                learning_rate=float(self.config.training.learning_rate),
                logging_steps=int(self.config.training.logging_steps),
                optim=str(self.config.training.optim),
                weight_decay=float(self.config.training.weight_decay),
                lr_scheduler_type=str(self.config.training.lr_scheduler_type),
                seed=int(self.config.training.seed),
                output_dir=str(self.config.training.output_dir),
                report_to=str(self.config.training.report_to),
            )

            # save_steps ã¨ save_total_limitãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¿½åŠ ï¼ˆå‹å¤‰æ›ä»˜ãï¼‰
            if self.config.training.save_steps is not None:
                sft_config.save_steps = int(self.config.training.save_steps)
            if self.config.training.save_total_limit is not None:
                sft_config.save_total_limit = int(self.config.training.save_total_limit)

            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å½¢å¼ã‚’ç¢ºèª
            sample_data = dataset[0] if len(dataset) > 0 else {}
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            if len(dataset) > 0:
                logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µãƒ³ãƒ—ãƒ«æ§‹é€ : {list(sample_data.keys())}")
                sample_text_length = len(sample_data.get('text', '')) if 'text' in sample_data else 0
                logger.info(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆé•·: {sample_text_length} æ–‡å­—")
            
            # ãƒ‡ãƒ¼ã‚¿å½¢å¼ã«å¿œã˜ãŸå‡¦ç†
            if 'messages' in sample_data:
                logger.warning("ChatMLå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
                logger.warning("æ¨å¥¨: training_dataset.json ã¾ãŸã¯ complete_dataset.json ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
                
                # ChatMLå½¢å¼ã‚’é€šå¸¸ã®textå½¢å¼ã«äº‹å‰å¤‰æ›
                try:
                    logger.info("ChatML â†’ text å½¢å¼å¤‰æ›ä¸­...")
                    converted_data = []
                    for example in dataset:
                        formatted_texts = self.format_chatml_messages(example)
                        converted_data.append({
                            'text': formatted_texts[0],  # ãƒªã‚¹ãƒˆã®æœ€åˆã®è¦ç´ ã‚’å–å¾—
                            'metadata': example.get('metadata', {})
                        })
                    
                    # æ–°ã—ã„Datasetã‚’ä½œæˆ
                    from datasets import Dataset
                    converted_dataset = Dataset.from_list(converted_data)
                    logger.info(f"âœ… ChatMLå¤‰æ›å®Œäº†: {len(converted_dataset)} ä»¶")
                    
                    # é€šå¸¸ã®textå½¢å¼ã¨ã—ã¦å‡¦ç†
                    trainer = SFTTrainer(
                        model=model,
                        tokenizer=tokenizer,
                        train_dataset=converted_dataset,
                        dataset_text_field="text",
                        max_seq_length=self.config.model.max_seq_length,
                        dataset_num_proc=1,  # ChatMLå¤‰æ›æ™‚ã¯å®‰å®šæ€§å„ªå…ˆ
                        packing=False,
                        args=sft_config,
                    )
                    
                except Exception as convert_error:
                    logger.error(f"ChatMLå¤‰æ›ã«å¤±æ•—: {convert_error}")
                    raise RuntimeError("ChatMLãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚training_dataset.jsonã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
                    
            elif 'text' in sample_data:
                # é€šå¸¸ã®textå½¢å¼ï¼ˆæ¨å¥¨ãƒ‘ã‚¹ï¼‰
                logger.info("âœ… é€šå¸¸textå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆæ¨å¥¨ï¼‰")
                
                # Tritonå•é¡Œå›é¿ã®ãŸã‚ä¿å®ˆçš„è¨­å®šã‚’ä½¿ç”¨
                dataset_num_proc = 1  # Tritonã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚1å›ºå®š
                packing = False       # packingã‚’ç„¡åŠ¹åŒ–
                
                logger.info(f"è¨­å®š: dataset_num_proc={dataset_num_proc}, packing={packing} (Tritonå•é¡Œå›é¿)")
                
                trainer = SFTTrainer(
                    model=model,
                    tokenizer=tokenizer,
                    train_dataset=dataset,
                    dataset_text_field=self.config.data.text_field,
                    max_seq_length=self.config.model.max_seq_length,
                    dataset_num_proc=dataset_num_proc,
                    packing=packing,
                    args=sft_config,
                )
            else:
                logger.error(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿å½¢å¼: {list(sample_data.keys())}")
                raise ValueError("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«textãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¾ãŸã¯messagesãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå¿…è¦ã§ã™")

            self.trainer = trainer
            logger.info("âœ…ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆå®Œäº†")
            return trainer
        
        except Exception as e:
            logger.error(f"âœ–ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def train(self) -> dict:
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ"""
        if self.trainer is None:
            raise ValueError("ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚create_trainer()ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        try:
            logger.info("ğŸš€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹...")

            self.training_stats = self.trainer.train()
            logger.info("âœ…ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†")
            return self.training_stats
        
        except Exception as e:
            logger.error(f"âœ–ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def get_training_summary(self) -> dict:
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        if self.training_stats is None:
            return {"error": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“"}
        
        runtime = self.training_stats.metrics.get('train_runtime', 0)

        return {
            "train_runtime_seconds": round(runtime, 1),
            "train_runtime_minutes": round(runtime / 60, 2),
            "train_samples_per_second": self.training_stats.metrics.get('train_samples_per_second', 0),
            "train_steps_per_second": self.training_stats.metrics.get('train_steps_per_second', 0),
            "total_flos": self.training_stats.metrics.get('total_flos', 0),
            "train_loss": self.training_stats.metrics.get('train_loss', 0),
        }