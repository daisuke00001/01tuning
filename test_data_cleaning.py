# ðŸ§ª ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
import json
import re
import os

def test_data_cleaning():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæä¾›ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŠœç²‹ï¼‰
    sample_data = {
        "patent_id": "7620367",
        "title": "ç²¾ç¥žéšœå®³åˆ†æžè£…ç½®",
        "text": "ç²¾ç¥žéšœå®³åˆ†æžè£…ç½® èª²é¡Œç²¾ç¥žéšœå®³ã§ã‚ã‚‹ã“ã¨ã‚’åˆ†æžã™ã‚‹ç²¾ç¥žéšœå®³åˆ†æžè£…ç½®ã‚’æä¾›ã™ã‚‹ã€‚è§£æ±ºæ‰‹æ®µç²¾ç¥žéšœå®³åˆ†æžè£…ç½®ã¯ã€ç²¾ç¥žéšœå®³ã§ã‚ã‚‹ã¨è¨ºæ–­ã•ã‚ŒãŸæ‚£è€…CHCHCHCHCHCHEMICAL6479MICCHEMICACHEMICACHEMICAL647864626461L6459MICACHEMICACHEMICACHEMICAL6458645364386434MICACHEMICAL64336424MICACHEMICAL64236414MICAL6413ECHEMICAL6415AL20å­¦ç¿’ç”¨å‹•ç”»ã‚’æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å­¦ç¿’ã•ã›ãŸç²¾ç¥žéšœå®³å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è¨˜æ†¶ã•ã›ã‚‹è¨˜æ†¶éƒ¨ã¨ã€åˆ†æžå¯¾è±¡è€…LECHEMICAL6460AL21åˆ†æžå¯¾è±¡å‹•ç”»ã‚’å–å¾—ã™ã‚‹å–å¾—éƒ¨ã¨ã€åˆ†æžå¯¾è±¡å‹•ç”»ã«ç²¾ç¥žéšœå®³å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’é©ç”¨ã—ã¦ã€åˆ†æžå¯¾è±¡è€…ãŒç²¾ç¥žéšœå®³ã§ã‚ã‚‹ã‹å¦ã‹ã‚’åˆ†æžã™ã‚‹åˆ†æžéƒ¨ã¨ã€LECHEMICAL6480AL00ã€‚"
    }
    
    print("ðŸ” ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)
    
    # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
    original_text = sample_data["text"]
    print(f"ðŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿:")
    print(f"  - æ–‡å­—æ•°: {len(original_text):,}")
    print(f"  - ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {original_text[:200]}...")
    
    # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°
    def clean_patent_text(text: str) -> str:
        """ç‰¹è¨±ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        if not isinstance(text, str):
            return ""
        
        # ç•°å¸¸ãªæ–‡å­—åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤åŽ»
        text = re.sub(r'CHEMICAL\d+', '', text)
        text = re.sub(r'LEGAL\d+', '', text)
        text = re.sub(r'MIC[A-Z]*', '', text)
        text = re.sub(r'CH{3,}', '', text)
        text = re.sub(r'AL\d+', '', text)
        text = re.sub(r'LE[A-Z]*', '', text)
        
        # é€£ç¶šã™ã‚‹åŒã˜æ–‡å­—ã‚’é™¤åŽ»
        text = re.sub(r'(.)\1{2,}', r'\1\1', text)
        
        # è¤‡æ•°ã®ç©ºç™½ã‚’å˜ä¸€ã«
        text = re.sub(r'\s+', ' ', text)
        
        # åˆ¶å¾¡æ–‡å­—ã‚’é™¤åŽ»
        text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', text)
        
        return text.strip()
    
    def limit_text_length(text: str, max_length: int = 1000) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’åˆ¶é™"""
        if len(text) > max_length:
            sentences = text.split('ã€‚')
            result = ""
            for sentence in sentences:
                if len(result + sentence + 'ã€‚') <= max_length:
                    result += sentence + 'ã€‚'
                else:
                    break
            return result if result else text[:max_length]
        return text
    
    # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
    cleaned_text = clean_patent_text(original_text)
    limited_text = limit_text_length(cleaned_text, 800)
    
    print(f"\nâœ… ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ:")
    print(f"  - æ–‡å­—æ•°: {len(limited_text):,}")
    print(f"  - çŸ­ç¸®çŽ‡: {(1 - len(limited_text)/len(original_text))*100:.1f}%")
    print(f"  - ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {limited_text[:300]}...")
    
    # å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    clean_dataset = [{
        "text": limited_text,
        "patent_id": sample_data["patent_id"],
        "title": sample_data["title"]
    }]
    
    return clean_dataset

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
test_dataset = test_data_cleaning()

# HuggingFace Datasetsã«å¤‰æ›ã—ã¦ãƒ†ã‚¹ãƒˆ
from datasets import Dataset
dataset = Dataset.from_list(test_dataset)

print(f"\nðŸŽ¯ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†:")
print(f"  - ãƒ‡ãƒ¼ã‚¿æ•°: {len(dataset)}")
print(f"  - ã‚­ãƒ¼: {list(dataset[0].keys())}")
print(f"  - ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(dataset[0]['text'])}")

print("\nâœ… ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Œäº†")
print("ðŸ’¡ ã“ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã‚’ãƒ†ã‚¹ãƒˆã§ãã¾ã™")