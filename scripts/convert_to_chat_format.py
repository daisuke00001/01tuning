#!/usr/bin/env python3
"""
ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã‚’TinySwallow-1.5B-Instructç”¨ã®chat templateå½¢å¼ã«å¤‰æ›
è«‹æ±‚é … â†’ userã€å®Ÿæ–½å½¢æ…‹ â†’ assistant ã®å¯¾è©±å½¢å¼ã«å¤‰æ›
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Any
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ===== å®šæ•°å®šç¾© =====
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œç´¢ã®å„ªå…ˆé †ä½
CLAIMS_SECTIONS = ['claims', 'claim']  # è«‹æ±‚é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå³å¯†ï¼‰
EMBODIMENT_SECTIONS = ['detailed_description', 'embodiment']  # å®Ÿæ–½å½¢æ…‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå³å¯†ï¼‰

# ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ¶é™
MAX_CLAIMS_LENGTH = 500      # è«‹æ±‚é …ã®æœ€å¤§æ–‡å­—æ•°
MAX_EMBODIMENT_LENGTH = 800  # å®Ÿæ–½å½¢æ…‹ã®æœ€å¤§æ–‡å­—æ•°
MIN_CLAIMS_LENGTH = 30       # è«‹æ±‚é …ã®æœ€å°æ–‡å­—æ•°  
MIN_EMBODIMENT_LENGTH = 100  # å®Ÿæ–½å½¢æ…‹ã®æœ€å°æ–‡å­—æ•°

# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
SYSTEM_PROMPT = """ã‚ãªãŸã¯ç‰¹è¨±ã®å°‚é–€å®¶ã§ã™ã€‚è«‹æ±‚é …ã‹ã‚‰å…·ä½“çš„ãªå®Ÿæ–½å½¢æ…‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""

# ç‰¹è¨±æ–‡æ›¸ãƒãƒ¼ã‚«ãƒ¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
PATENT_MARKER_PATTERN = r'ã€[^ã€‘]*ã€‘'  # ã€èª²é¡Œã€‘ã€è§£æ±ºæ‰‹æ®µã€‘ç­‰ã®ä¸€èˆ¬ãƒãƒ¼ã‚«ãƒ¼
PATENT_PARAGRAPH_PATTERN = r'ã€\d{4}ã€‘'  # ã€0010ã€‘ã€0011ã€‘ç­‰ã®æ®µè½ç•ªå·
PATENT_SECTION_PATTERN = r'ã€[^ã€‘\d][^ã€‘]*ã€‘'  # ã€ç™ºæ˜ã‚’å®Ÿæ–½ã™ã‚‹å½¢æ…‹ã€‘ç­‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆæ•°å­—ä»¥å¤–ã§å§‹ã¾ã‚‹ï¼‰
PATENT_ALL_PATTERN = r'ã€[^ã€‘]*ã€‘'  # å…¨ã¦ã®ã€ã€‘ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆçµ±åˆï¼‰

class PatentChatFormatter:
    """ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã‚’chatå½¢å¼ã«å¤‰æ›ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.cleaned_dir = self.project_root / "data" / "cleaned"
        self.chat_dir = self.project_root / "data" / "chat_format"
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        self.chat_dir.mkdir(exist_ok=True)
        
    def extract_claims_and_implementations(self, data: List[Dict]) -> List[Dict]:
        """
        ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è«‹æ±‚é …ã¨å®Ÿæ–½å½¢æ…‹ã®ãƒšã‚¢ã‚’æŠ½å‡º
        
        ãƒ­ã‚¸ãƒƒã‚¯è©³ç´°:
        1. patent_idã”ã¨ã«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        2. è«‹æ±‚é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å³å¯†ã«æ¤œç´¢: claims > claim ï¼ˆabstractã¯é™¤å¤–ï¼‰
        3. å®Ÿæ–½å½¢æ…‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å³å¯†ã«æ¤œç´¢: detailed_description > embodiment ï¼ˆä»–ã¯é™¤å¤–ï¼‰
        4. ä¸¡æ–¹ãŒå­˜åœ¨ã—ã€ã‹ã¤æœ€ä½æ–‡å­—æ•°ã‚’æº€ãŸã™å ´åˆã®ã¿ãƒšã‚¢ä½œæˆ
        5. è«‹æ±‚é …â†’å®Ÿæ–½å½¢æ…‹ã®ç”Ÿæˆã«å¿…è¦ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿ã‚’ä½¿ç”¨
        """
        
        # patent_idã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        patents_by_id = {}
        for item in data:
            patent_id = item.get('patent_id', 'unknown')
            if patent_id not in patents_by_id:
                patents_by_id[patent_id] = {}
            
            section = item.get('section', 'unknown')
            text = item.get('text', '')
            
            patents_by_id[patent_id][section] = text
        
        logger.info(f"ã‚°ãƒ«ãƒ¼ãƒ—åŒ–å®Œäº†: {len(patents_by_id)}ä»¶ã®ç‰¹è¨±")
        
        # è«‹æ±‚é …ã¨å®Ÿæ–½å½¢æ…‹ã®ãƒšã‚¢ã‚’ä½œæˆ
        chat_pairs = []
        skipped_stats = {
            'no_claims': 0,
            'no_implementation': 0, 
            'too_short': 0,
            'success': 0
        }
        
        for patent_id, sections in patents_by_id.items():
            # åˆ©ç”¨å¯èƒ½ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
            available_sections = list(sections.keys())
            logger.debug(f"Patent {patent_id}: {available_sections}")
            
            # è«‹æ±‚é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å³å¯†ã«æ¤œç´¢ï¼ˆå®šæ•°ä½¿ç”¨ï¼‰
            claims_section = None
            claims_text = ""
            
            for section_name in CLAIMS_SECTIONS:
                if section_name in sections and sections[section_name].strip():
                    claims_section = section_name
                    claims_text = sections[section_name]
                    logger.debug(f"è«‹æ±‚é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¡ç”¨: {patent_id} - {section_name}")
                    break
            
            # å®Ÿæ–½å½¢æ…‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å³å¯†ã«æ¤œç´¢ï¼ˆå®šæ•°ä½¿ç”¨ï¼‰
            implementation_section = None
            implementation_text = ""
            
            for section_name in EMBODIMENT_SECTIONS:
                if section_name in sections and sections[section_name].strip():
                    implementation_section = section_name
                    implementation_text = sections[section_name]
                    logger.debug(f"å®Ÿæ–½å½¢æ…‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¡ç”¨: {patent_id} - {section_name}")
                    break
            
            # ãƒšã‚¢ä½œæˆã®åˆ¤å®š
            if not claims_text:
                skipped_stats['no_claims'] += 1
                logger.debug(f"è«‹æ±‚é …ãªã—ã§ã‚¹ã‚­ãƒƒãƒ—: {patent_id}")
                continue
                
            if not implementation_text:
                skipped_stats['no_implementation'] += 1  
                logger.debug(f"å®Ÿæ–½å½¢æ…‹ãªã—ã§ã‚¹ã‚­ãƒƒãƒ—: {patent_id}")
                continue
            
            # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ï¼ˆæ–‡å­—æ•°åˆ¶é™å¯¾å¿œï¼‰
            claims_text = self.preprocess_claims(claims_text)
            implementation_text = self.preprocess_implementation(implementation_text)
            
            # æœ€ä½é•·ãƒã‚§ãƒƒã‚¯ï¼ˆå‰å‡¦ç†å¾Œã€å®šæ•°ä½¿ç”¨ï¼‰
            if len(claims_text) >= MIN_CLAIMS_LENGTH and len(implementation_text) >= MIN_EMBODIMENT_LENGTH:
                chat_pairs.append({
                    'patent_id': patent_id,
                    'claims_section': claims_section,
                    'implementation_section': implementation_section,
                    'user_message': claims_text,
                    'assistant_message': implementation_text
                })
                skipped_stats['success'] += 1
                logger.debug(f"ãƒšã‚¢ä½œæˆæˆåŠŸ: {patent_id}")
            else:
                skipped_stats['too_short'] += 1
                logger.debug(f"ãƒ†ã‚­ã‚¹ãƒˆé•·ä¸è¶³ã§ã‚¹ã‚­ãƒƒãƒ—: {patent_id} (claims:{len(claims_text)}, impl:{len(implementation_text)})")
        
        # çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›
        logger.info(f"ãƒšã‚¢ä½œæˆçµ±è¨ˆ:")
        logger.info(f"  - æˆåŠŸ: {skipped_stats['success']}")
        logger.info(f"  - è«‹æ±‚é …ãªã—: {skipped_stats['no_claims']}")
        logger.info(f"  - å®Ÿæ–½å½¢æ…‹ãªã—: {skipped_stats['no_implementation']}")
        logger.info(f"  - æ–‡å­—æ•°ä¸è¶³: {skipped_stats['too_short']}")
        logger.info(f"æŠ½å‡ºã•ã‚ŒãŸãƒšã‚¢æ•°: {len(chat_pairs)}")
        return chat_pairs
    
    def preprocess_claims(self, text: str) -> str:
        """
        è«‹æ±‚é …ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
        
        ç‰¹è¨±æ–‡æ›¸ã®å®Ÿéš›ã®æ§‹é€ ã«å¯¾å¿œ:
        1. ã€è«‹æ±‚é …1ã€‘ã€è«‹æ±‚é …2ã€‘ç­‰ã§åŒºåˆ‡ã‚‰ã‚Œã‚‹
        2. å„è«‹æ±‚é …å˜ä½ã§å‡¦ç†
        3. è«‹æ±‚é …å˜ä½ã§é©åˆ‡ãªé•·ã•ã«åˆ¶é™
        """
        if not text:
            return ""
        
        # ä½™åˆ†ãªç©ºç™½ã‚’é™¤å»
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        # æ–‡å­—æ•°åˆ¶é™ï¼ˆå®šæ•°ä½¿ç”¨ï¼‰
        if len(text) <= MAX_CLAIMS_LENGTH:
            return text
        
        # ã€è«‹æ±‚é …1ã€‘ã€è«‹æ±‚é …2ã€‘ç­‰ã§åˆ†å‰²
        claims_pattern = r'ã€è«‹æ±‚é …\d+ã€‘'
        claims_blocks = re.split(claims_pattern, text)
        claims_markers = re.findall(claims_pattern, text)
        
        result = ""
        
        # å„è«‹æ±‚é …ã‚’é †æ¬¡è¿½åŠ 
        for i, block in enumerate(claims_blocks):
            if not block.strip():
                continue
                
            # è«‹æ±‚é …ç•ªå·ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            claim_marker = claims_markers[i-1] if i > 0 and i-1 < len(claims_markers) else ""
            potential_claim = claim_marker + block.strip()
            potential_result = result + potential_claim
            
            if len(potential_result) <= MAX_CLAIMS_LENGTH:
                result = potential_result
            else:
                # ç¾åœ¨ã®çµæœãŒç©ºã§ãªã„å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
                if result:
                    break
                # çµæœãŒç©ºã®å ´åˆã¯æœ€åˆã®è«‹æ±‚é …ã ã‘ã§ã‚‚å¼·åˆ¶çš„ã«å«ã‚ã‚‹
                else:
                    result = potential_claim[:MAX_CLAIMS_LENGTH-3] + '...'
                    break
        
        # ã¾ã çµæœãŒç©ºã®å ´åˆï¼ˆå®‰å…¨ç­–: è«‹æ±‚é …ãƒ‘ã‚¿ãƒ¼ãƒ³ã§åˆ†å‰²ã§ããªã„å ´åˆï¼‰
        if not result:
            # ä¸€èˆ¬çš„ãªã€****ã€‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã§åˆ†å‰²ã‚’è©¦è¡Œ
            general_blocks = re.split(PATENT_ALL_PATTERN, text)
            general_markers = re.findall(PATENT_ALL_PATTERN, text)
            
            for i, block in enumerate(general_blocks):
                if not block.strip():
                    continue
                    
                marker = general_markers[i-1] if i > 0 and i-1 < len(general_markers) else ""
                potential_block = marker + block.strip()
                
                if len(potential_block) <= MAX_CLAIMS_LENGTH:
                    result = potential_block
                    break
                else:
                    result = potential_block[:MAX_CLAIMS_LENGTH-3] + '...'
                    break
        
        # æœ€çµ‚å®‰å…¨ç­–
        if not result:
            result = text[:MAX_CLAIMS_LENGTH-3] + '...'
        
        logger.debug(f"è«‹æ±‚é …å‰å‡¦ç†: {len(text)} â†’ {len(result)} æ–‡å­—")
        return result
    
    def preprocess_implementation(self, text: str) -> str:
        """
        å®Ÿæ–½å½¢æ…‹ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
        
        ç‰¹è¨±æ–‡æ›¸ã®å®Ÿéš›ã®æ§‹é€ ã«å¯¾å¿œ:
        1. ã€ç™ºæ˜ã‚’å®Ÿæ–½ã™ã‚‹å½¢æ…‹ã€‘ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰é–‹å§‹
        2. ã€0010ã€‘ã€0011ã€‘ç­‰ã®æ®µè½ç•ªå·ã§åŒºåˆ‡ã‚‰ã‚Œã‚‹
        3. æ®µè½å˜ä½ã§é©åˆ‡ãªé•·ã•ã«åˆ¶é™
        """
        if not text:
            return ""
        
        # ä½™åˆ†ãªç©ºç™½ã‚’é™¤å»
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        # æ–‡å­—æ•°åˆ¶é™ï¼ˆå®šæ•°ä½¿ç”¨ï¼‰
        if len(text) <= MAX_EMBODIMENT_LENGTH:
            return text
        
        # ã€ç™ºæ˜ã‚’å®Ÿæ–½ã™ã‚‹å½¢æ…‹ã€‘ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡º
        embodiment_start = re.search(r'ã€ç™ºæ˜ã‚’å®Ÿæ–½ã™ã‚‹å½¢æ…‹ã€‘', text)
        if embodiment_start:
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹ä½ç½®ã‹ã‚‰å‡¦ç†
            text = text[embodiment_start.start():]
            
        # æ®µè½ç•ªå·ã€0010ã€‘ã€0011ã€‘ç­‰ã§åˆ†å‰²
        paragraphs = re.split(PATENT_PARAGRAPH_PATTERN, text)
        paragraph_numbers = re.findall(PATENT_PARAGRAPH_PATTERN, text)
        
        result = ""
        
        # å„æ®µè½ã‚’é †æ¬¡è¿½åŠ 
        for i, paragraph in enumerate(paragraphs):
            if not paragraph.strip():
                continue
                
            # æ®µè½ç•ªå·ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            paragraph_num = paragraph_numbers[i-1] if i > 0 and i-1 < len(paragraph_numbers) else ""
            
            # æœ€åˆã®æ®µè½ã®å ´åˆã€ã€ç™ºæ˜ã‚’å®Ÿæ–½ã™ã‚‹å½¢æ…‹ã€‘ã‚’å«ã‚ã‚‹å¯èƒ½æ€§
            if i == 0 and 'ã€ç™ºæ˜ã‚’å®Ÿæ–½ã™ã‚‹å½¢æ…‹ã€‘' in paragraph:
                potential_paragraph = paragraph.strip()
            else:
                potential_paragraph = paragraph_num + paragraph.strip()
                
            potential_result = result + potential_paragraph
            
            if len(potential_result) <= MAX_EMBODIMENT_LENGTH:
                result = potential_result
            else:
                # ç¾åœ¨ã®çµæœãŒç©ºã§ãªã„å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
                if result:
                    break
                # çµæœãŒç©ºã®å ´åˆã¯æœ€åˆã®æ®µè½ã ã‘ã§ã‚‚å¼·åˆ¶çš„ã«å«ã‚ã‚‹
                else:
                    result = potential_paragraph[:MAX_EMBODIMENT_LENGTH-3] + '...'
                    break
        
        # ã¾ã çµæœãŒç©ºã®å ´åˆï¼ˆå®‰å…¨ç­–: æ®µè½ç•ªå·ãƒ‘ã‚¿ãƒ¼ãƒ³ã§åˆ†å‰²ã§ããªã„å ´åˆï¼‰
        if not result:
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åã€****ã€‘ã§åˆ†å‰²ã‚’è©¦è¡Œ
            section_blocks = re.split(PATENT_SECTION_PATTERN, text)
            section_markers = re.findall(PATENT_SECTION_PATTERN, text)
            
            for i, block in enumerate(section_blocks):
                if not block.strip():
                    continue
                    
                marker = section_markers[i-1] if i > 0 and i-1 < len(section_markers) else ""
                potential_block = marker + block.strip()
                
                if len(potential_block) <= MAX_EMBODIMENT_LENGTH:
                    result = potential_block
                    break
                else:
                    result = potential_block[:MAX_EMBODIMENT_LENGTH-3] + '...'
                    break
        
        # æœ€çµ‚å®‰å…¨ç­–
        if not result:
            result = text[:MAX_EMBODIMENT_LENGTH-3] + '...'
        
        logger.debug(f"å®Ÿæ–½å½¢æ…‹å‰å‡¦ç†: {len(text)} â†’ {len(result)} æ–‡å­—")
        return result
    
    def create_chat_template(self, user_message: str, assistant_message: str) -> str:
        """Chat templateå½¢å¼ã‚’ä½œæˆï¼ˆå®šæ•°ä½¿ç”¨ï¼‰"""
        
        # TinySwallow-1.5B-Instructç”¨ã®chat template
        chat_template = f"""<|im_start|>system
{SYSTEM_PROMPT}<|im_end|>
<|im_start|>user
{user_message}<|im_end|>
<|im_start|>assistant
{assistant_message}<|im_end|>"""
        
        return chat_template
    
    def convert_to_chat_format(self, input_file: str, output_file: str):
        """ãƒ¡ã‚¤ãƒ³å¤‰æ›å‡¦ç†"""
        
        input_path = self.cleaned_dir / input_file
        output_path = self.chat_dir / output_file
        
        logger.info(f"å¤‰æ›é–‹å§‹: {input_path} â†’ {output_path}")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        try:
            with open(input_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æ•°: {len(data)}")
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        # ãƒšã‚¢æŠ½å‡º
        chat_pairs = self.extract_claims_and_implementations(data)
        
        if not chat_pairs:
            logger.error("æœ‰åŠ¹ãªãƒšã‚¢ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # Chat formatå¤‰æ›
        chat_dataset = []
        
        for i, pair in enumerate(chat_pairs):
            try:
                chat_text = self.create_chat_template(
                    pair['user_message'],
                    pair['assistant_message']
                )
                
                chat_item = {
                    "text": chat_text,
                    "patent_id": pair['patent_id'],
                    "claims_section": pair['claims_section'],
                    "implementation_section": pair['implementation_section']
                }
                
                chat_dataset.append(chat_item)
                
                if (i + 1) % 10 == 0:
                    logger.info(f"å¤‰æ›é€²æ—: {i + 1}/{len(chat_pairs)}")
                    
            except Exception as e:
                logger.warning(f"ãƒšã‚¢ {i} ã®å¤‰æ›ã§ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # ä¿å­˜
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(chat_dataset, f, ensure_ascii=False, indent=2)
            
            logger.info(f"å¤‰æ›å®Œäº†: {output_path}")
            logger.info(f"å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿æ•°: {len(chat_dataset)}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¡¨ç¤º
            file_size = output_path.stat().st_size / (1024 * 1024)
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} MB")
            
            # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
            if chat_dataset:
                sample = chat_dataset[0]
                logger.info("ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒƒãƒˆ:")
                logger.info(f"ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(sample['text'])}")
                logger.info(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:\n{sample['text'][:300]}...")
                
        except Exception as e:
            logger.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def run_conversion(self):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œå‡¦ç†"""
        logger.info("=" * 60)
        logger.info("Chat Formatå¤‰æ›é–‹å§‹")
        logger.info("=" * 60)
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
        json_files = list(self.cleaned_dir.glob("cleaned_*.json"))
        
        if not json_files:
            logger.error(f"ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.cleaned_dir}")
            return
        
        logger.info(f"è¦‹ã¤ã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(json_files)}")
        for file_path in json_files:
            logger.info(f"  - {file_path.name}")
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›
        conversions = [
            ("cleaned_patents_small.json", "chat_patents_small.json"),
            ("cleaned_patents_medium.json", "chat_patents_medium.json"),
            ("cleaned_training_dataset.json", "chat_training_dataset.json"),
        ]
        
        for input_file, output_file in conversions:
            input_path = self.cleaned_dir / input_file
            if input_path.exists():
                self.convert_to_chat_format(input_file, output_file)
            else:
                logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_file}")
        
        logger.info("=" * 60)
        logger.info("Chat Formatå¤‰æ›å®Œäº†")
        logger.info("=" * 60)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    formatter = PatentChatFormatter()
    formatter.run_conversion()

if __name__ == "__main__":
    main()