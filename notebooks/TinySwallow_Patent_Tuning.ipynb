{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNi/t8fff/+oh+9TBuOQ1Rl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisuke00001/01tuning/blob/main/notebooks/TinySwallow_Patent_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TinySwallow特許データ LoRAファインチューニング専用ノートブック\n"
      ],
      "metadata": {
        "id": "ySSArs5y8K85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 環境とライブラリのセットアップ"
      ],
      "metadata": {
        "id": "hkArpSia-djD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gxHWyX1h0Dq9"
      },
      "outputs": [],
      "source": [
        "# 実行環境の確認とgithubリポジトリのクローン\n",
        "import os\n",
        "import subprocess\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 自動リロード設定（初回のみ）\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# 2. 更新があるたびに実行\n",
        "!git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEjTKHUaO_Wz",
        "outputId": "560f3e4b-ae19-4149-cbf9-2657fb552af5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (5/5), 1.11 KiB | 1.11 MiB/s, done.\n",
            "From https://github.com/daisuke00001/01tuning\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   00404b7..0f6cac9  main       -> origin/main\n",
            "Updating 00404b7..0f6cac9\n",
            "Fast-forward\n",
            " src/config.py      | 19 \u001b[32m+++++++++++++++++++\u001b[m\n",
            " src/model_utils.py | 26 \u001b[32m+++++++++++++++++++++++++\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 44 insertions(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUの確認\n",
        "def setup_patent_environment():\n",
        "    \"\"\"特許データ学収容Google Colab環境をセットアップ\"\"\"\n",
        "    print(\"特許データ専用環境をセットアップ中...\")\n",
        "\n",
        "    # GPU確認\n",
        "    if not os.path.exists('/opt/bin/nvidia-smi'):\n",
        "       print(\"GPU環境が検出されません。ランタイムタイプをGPUに変更してください。\")\n",
        "       return False\n",
        "\n",
        "    # リポジトリクローン\n",
        "    repo_url = \"https://github.com/daisuke00001/01tuning.git\"\n",
        "    if os.path.exists(\"01tuning\"):\n",
        "        print(\"📁 リポジトリが既に存在します。最新版に更新中...\")\n",
        "        subprocess.run([\"git\", \"-C\", \"01tuning\", \"pull\"], check=True)\n",
        "    else:\n",
        "        print(f\"📁 リポジトリをクローン中: {repo_url}\")\n",
        "        subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
        "\n",
        "    # 作業ディレクトリに移動\n",
        "    os.chdir(\"01tuning\")\n",
        "\n",
        "    # Pythonパスに追加\n",
        "    if \"/content/01tuning/src\" not in sys.path:\n",
        "        sys.path.append(\"/content/01tuning/src\")\n",
        "\n",
        "    print(\"✅ 特許データ学習環境セットアップ完了\")\n",
        "    return True\n",
        "\n",
        "# セットアップ実行\n",
        "setup_patent_environment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq3IroC01_5B",
        "outputId": "5fd7dce8-4335-47d9-cf1c-6771c24eab0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特許データ専用環境をセットアップ中...\n",
            "📁 リポジトリをクローン中: https://github.com/daisuke00001/01tuning.git\n",
            "✅ 特許データ学習環境セットアップ完了\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ライブラリインストール"
      ],
      "metadata": {
        "id": "zqSIn8XmJQUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab専用のライブラリインストール\n",
        "%%capture\n",
        "# Unslothとその依存関係\n",
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth\n",
        "\n",
        "# ライブラリエラー対応\n",
        "!pip install xformers\n",
        "!pip uninstall torchvision -y\n",
        "!pip install torchvision --no-cache-dir\n",
        "\n",
        "# 特許データ処理専用ライブラリ\n",
        "!pip install lxml beautifulsoup4 xmltodict\n",
        "!pip install nltk rouge-score sacrebleu\n",
        "!pip install openpyxl\n",
        "\n",
        "# その他の依存関係\n",
        "!pip install PyYAML\n",
        "\n",
        "print(\"📦 特許データ処理用ライブラリインストール完了\")"
      ],
      "metadata": {
        "id": "QK932-njJOEC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 特許専用設定の読み込み"
      ],
      "metadata": {
        "id": "DyOQcXRKJdWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from src.config import Config\n",
        "\n",
        "config_path = \"configs/patent_config.yaml\"\n",
        "config = Config.load_from_yaml(config_path)\n",
        "\n",
        "print(\"⚙️ 特許データ専用設定を読み込み中...\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"📄 設定ファイル: {config_path}\")\n",
        "print(f\"🤖 モデル: {config.model.name}\")\n",
        "print(f\"📊 データセット: {config.dataset.name}\")\n",
        "print(f\"🔧 最大シーケンス長: {config.model.max_seq_length}\")\n",
        "print(f\"📈 最大ステップ数: {config.training.max_steps}\")\n",
        "print(f\"⚡ バッチサイズ: {config.training.per_device_train_batch_size}\")\n",
        "print(f\"🎯 学習率: {config.training.learning_rate}\")\n",
        "print(f\"🔗 LoRAランク: {config.lora.r}\")\n",
        "print(f\"📋 対象モジュール: {', '.join(config.lora.target_modules[:3])}...\")\n",
        "\n",
        "print(\"\\n🏭 特許データ固有設定:\")\n",
        "print(f\"📄 特許文書最大長: {config.dataset.max_patent_length}\")\n",
        "print(f\"📝 実施形態最大長: {config.dataset.max_implementation_length}\")\n",
        "print(f\"🧹 参照除去: {config.dataset.remove_references}\")\n",
        "print(f\"✨ フォーマット整理: {config.dataset.clean_formatting}\")\n",
        "print(f\"📊 評価メトリクス: {', '.join(config.evaluation.metrics)}\")\n",
        "\n",
        "print(\"\\n✅ 特許専用設定読み込み完了\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRjZ43tyJfzV",
        "outputId": "2fcc9ca5-f47e-4312-d869-471d2d4e8f5a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ 特許データ専用設定を読み込み中...\n",
            "==================================================\n",
            "📄 設定ファイル: configs/patent_config.yaml\n",
            "🤖 モデル: SakanaAI/TinySwallow-1.5B-Instruct\n",
            "📊 データセット: patent_japanese\n",
            "🔧 最大シーケンス長: 2048\n",
            "📈 最大ステップ数: 200\n",
            "⚡ バッチサイズ: 1\n",
            "🎯 学習率: 3e-05\n",
            "🔗 LoRAランク: 16\n",
            "📋 対象モジュール: q_proj, v_proj, k_proj...\n",
            "\n",
            "🏭 特許データ固有設定:\n",
            "📄 特許文書最大長: 2048\n",
            "📝 実施形態最大長: 1024\n",
            "🧹 参照除去: True\n",
            "✨ フォーマット整理: True\n",
            "📊 評価メトリクス: rouge, bleu, patent_implementation_quality\n",
            "\n",
            "✅ 特許専用設定読み込み完了\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルの読み込みとLoRA設定"
      ],
      "metadata": {
        "id": "FV5HnVQqJzYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.model_utils import ModelManager\n",
        "import torch\n",
        "\n",
        "print(\"TinySwallow-1.5B モデル読み込み中...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# モデルマネージャークラスの初期化\n",
        "model_manager = ModelManager(config)\n",
        "\n",
        "# メモリ使用量(読み込み前)\n",
        "initial_memory = model_manager.get_memory_stats()\n",
        "print(f\"💾 最終メモリ使用量: {initial_memory['used']:.2f}GB / {initial_memory['total']:.2f}GB ({initial_memory['percentage']:.1f}%)\")\n",
        "\n",
        "# ベースモデルとトークナイザーの読み込み\n",
        "model, tokenizer = model_manager.load_model()\n",
        "\n",
        "# LoRA設定（特許データ専用）\n",
        "print(\"\\n🔧 特許データ専用LoRA設定を適用中...\")\n",
        "model = model_manager.setup_lora()\n",
        "\n",
        "# メモリ使用量（読み込み後）\n",
        "loaded_memory = model_manager.get_memory_stats()\n",
        "print(f\"💾 最終メモリ使用量: {loaded_memory['used']:.2f}GB / {loaded_memory['total']:.2f}GB ({loaded_memory['percentage']:.1f}%)\")\n",
        "\n",
        "# モデル情報の表示\n",
        "model_info = model_manager.get_model_info()  # ✅ 正しいメソッド\n",
        "print(f\"\\n🔍 モデル詳細情報:\")\n",
        "print(f\"📊 総パラメータ数: {model_info['total_params']:,}\")\n",
        "print(f\"🔧 学習可能パラメータ数: {model_info['trainable_params']:,}\")\n",
        "print(f\"📈 学習可能パラメータ割合: {model_info['trainable_percentage']:.2f}%\")\n",
        "\n",
        "print(\"\\n✅ TinySwallow-1.5B + 特許専用LoRA設定完了\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpTe2MjkJ202",
        "outputId": "0b6aff2f-9a13-49cc-e54a-76feaa9f0249"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TinySwallow-1.5B モデル読み込み中...\n",
            "==================================================\n",
            "💾 最終メモリ使用量: 1.57GB / 14.74GB (10.6%)\n",
            "==((====))==  Unsloth 2025.7.11: Fast Qwen2 patching. Transformers: 4.54.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "\n",
            "🔧 特許データ専用LoRA設定を適用中...\n",
            "💾 最終メモリ使用量: 2.91GB / 14.74GB (19.7%)\n",
            "\n",
            "🔍 モデル詳細情報:\n",
            "📊 総パラメータ数: 907,081,216\n",
            "🔧 学習可能パラメータ数: 18,464,768\n",
            "📈 学習可能パラメータ割合: 2.04%\n",
            "\n",
            "✅ TinySwallow-1.5B + 特許専用LoRA設定完了\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの準備"
      ],
      "metadata": {
        "id": "2f2WEcQeLAKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.data_processing import DataProcessor\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"特許データセットを準備中...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# データプロセッサーの初期化\n",
        "data_processor = DataProcessor(config, tokenizer)\n",
        "\n",
        "# 特許データの自動検出\n",
        "print(\"🔍 特許データファイルを検索中...\")\n",
        "data_files = data_processor.discover_patent_data()\n",
        "\n",
        "if not data_files:\n",
        "    print(\"⚠ 特許データが見つかりません。サンプルデータを作成します...\")\n",
        "\n",
        "    # 特許データのサンプルを作成\n",
        "    sample_patent_data = [\n",
        "        {\n",
        "            \"text\": \"<|im_start|>system\\n専門家AIとして、特許の請求項から実施形態を生成してください。具体的で技術的に正確な内容にしてください。<|im_end|>\\n<|im_start|>user\\n以下の特許請求項から「発明を実施するための形態」を生成してください。\\n\\n### 特許請求項:\\n【請求項１】\\n基板と、該基板上に形成された半導体層と、該半導体層上に形成された絶縁層と、該絶縁層上に形成された導電層とを有する半導体装置。\\n\\n### 発明を実施するための形態:<|im_end|>\\n<|im_start|>assistant\\n【０００８】本発明の半導体装置について、図面を参照して詳細に説明する。\\n\\n【０００９】図１に示すように、本実施形態の半導体装置１０は、シリコン基板１１上に形成されている。シリコン基板１１は、単結晶シリコンからなり、厚さは約５００μｍとすることができる。\\n\\n【００１０】半導体層１２は、シリコン基板１１上に形成されており、厚さは約１μｍとすることができる。半導体層１２は、ｎ型またはｐ型の不純物が添加されたシリコン層である。\\n\\n【００１１】絶縁層１３は、半導体層１２上に形成されており、酸化シリコン（ＳｉＯ２）からなる。絶縁層１３の厚さは約１００ｎｍとすることができる。\\n\\n【００１２】導電層１４は、絶縁層１３上に形成されており、アルミニウムまたは銅からなる配線層である。導電層１４の厚さは約０．５μｍとすることができる。<|im_end|>\",\n",
        "            \"metadata\": {\n",
        "                \"patent_id\": \"sample_semiconductor_001\",\n",
        "                \"field\": \"semiconductor\",\n",
        "                \"claims_length\": 156,\n",
        "                \"implementation_length\": 485,\n",
        "                \"total_length\": 892\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"text\": \"<|im_start|>system\\n専門家AIとして、特許の請求項から実施形態を生成してください。具体的で技術的に正確な内容にしてください。<|im_end|>\\n<|im_start|>user\\n以下の特許請求項から「発明を実施するための形態」を生成してください。\\n\\n### 特許請求項:\\n【請求項１】\\n有機化合物Ａと有機化合物Ｂとを反応させて目的化合物Ｃを製造する方法であって、反応温度が５０℃～１５０℃であることを特徴とする製造方法。\\n\\n### 発明を実施するための形態:<|im_end|>\\n<|im_start|>assistant\\n【０００８】本発明の化合物製造方法について詳細に説明する。\\n\\n【０００９】有機化合物Ａとしては、分子量が１００～５００の範囲にある芳香族化合物が好ましい。具体的には、ベンゼン誘導体、ナフタレン誘導体などが挙げられる。\\n\\n【００１０】有機化合物Ｂとしては、官能基を有するアルキル化合物が適している。炭素数が２～１０のアルキル基を有する化合物が特に好ましい。\\n\\n【００１１】反応は、不活性ガス雰囲気下で行うことが望ましい。窒素ガスまたはアルゴンガス雰囲気下で反応を進行させることにより、副反応を抑制できる。\\n\\n【００１２】反応温度は５０℃～１５０℃の範囲で制御する。好ましくは８０℃～１２０℃である。この温度範囲において、目的化合物Ｃの収率が最も高くなる。<|im_end|>\",\n",
        "            \"metadata\": {\n",
        "                \"patent_id\": \"sample_chemical_001\",\n",
        "                \"field\": \"chemical\",\n",
        "                \"claims_length\": 178,\n",
        "                \"implementation_length\": 521,\n",
        "                \"total_length\": 950\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # サンプルデータを保存\n",
        "    os.makedirs(\"data/processed\", exist_ok=True)\n",
        "    with open(\"data/processed/patent_sample.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        for item in sample_patent_data:\n",
        "          f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    dataset_path = \"data/processed/patent_sample.json\"\n",
        "    print(f\"✅ サンプル特許データを作成： {dataset_path}\")\n",
        "else:\n",
        "  # 実際の特許データが見つかった場合\n",
        "  print(f\"✅ 特許データファイルを発見: {len(data_files)}個\")\n",
        "  for file_path in data_files[:3]:  # 最初の3個を表示\n",
        "      print(f\"  📄 {file_path}\")\n",
        "  if len(data_files) > 3:\n",
        "     print(f\"... 他{len(data_files)-3}個\")\n",
        "\n",
        "# データセットの読み込みと前処理\n",
        "print(\"\\n🔄 特許データセットを読み込み中...\")\n",
        "dataset = data_processor.load_patent_dataset()\n",
        "\n",
        "print(f\"\\n📊 特許データセット情報:\")\n",
        "print(f\"📄 総サンプル数: {len(dataset):,}\")\n",
        "print(f\"📏 平均トークン長: {sum(len(tokenizer.encode(sample['text'])) for sample in dataset) // len(dataset):,}\")\n",
        "\n",
        "# データセットのサンプルを表示\n",
        "print(f\"\\n📝 データセットサンプル（最初の1件）:\")\n",
        "print(\"-\" * 80)\n",
        "sample_text = dataset[0]['text']\n",
        "if len(sample_text) > 500:\n",
        "    print(sample_text[:500] + \"...\")\n",
        "else:\n",
        "    print(sample_text)\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(\"\\n✅ 特許データセット準備完了\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ShdiSWW8LDms",
        "outputId": "965e50b3-f458-468e-e07d-fb540941200d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特許データセットを準備中...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 特許データファイルを検索中...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataProcessor' object has no attribute 'discover_patent_data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1871856455.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 特許データの自動検出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔍 特許データファイルを検索中...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscover_patent_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataProcessor' object has no attribute 'discover_patent_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## トレーニングの準備と実行"
      ],
      "metadata": {
        "id": "d9pqdb1TL82h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.training_utils import TrainingManager\n",
        "import time\n",
        "\n",
        "print(\"🚀 特許データ専用トレーニング開始...\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  📄 データセット: 特許文書 ({len(dataset):,}件)\")\n",
        "print(f\"  🤖 モデル: {config.model.name}\")\n",
        "print(f\"  📈 ステップ数: {config.training.max_steps}\")\n",
        "print(f\"  ⚡ バッチサイズ: {config.training.per_device_train_batch_size}\")\n",
        "print(f\"  🎯 学習率: {config.training.learning_rate}\")\n",
        "print(f\"  🔗 LoRAランク: {config.lora.r}\")\n",
        "print(f\"  📏 最大シーケンス長: {config.model.max_seq_length}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# トレーニングマネージャークラスの初期化\n",
        "training_manager = TrainingManager(config)\n",
        "\n",
        "# トレーナーの作成\n",
        "trainer = training_manager.create_trainer(model, tokenizer, dataset)\n",
        "\n",
        "# トレーニング開始時刻を記録\n",
        "start_time = time.time()\n",
        "\n",
        "# トレーニング実行\n",
        "print(\"\\n特許データ学習を開始します...\")\n",
        "training_stats = training_manager.train()\n",
        "\n",
        "# 実行時間の計算\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "print(f\"\\n✅ 特許データ専用トレーニング完了!\")\n",
        "print(f\"実行時間: {training_time/60:.1f}分\")"
      ],
      "metadata": {
        "id": "3Ae-xlPFW5Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## トレーニング結果を確認"
      ],
      "metadata": {
        "id": "VCJUso_eMheJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# トレーニング結果とメモリ使用量を確認\n",
        "\n",
        "summary = training_manager.get_training_summary()\n",
        "final_memory = model_manager.get_memory_stats()\n",
        "\n",
        "print(f\"\\n📊 特許データ学習結果:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"📈 最終Loss: {summary['train_loss']:.4f}\")\n",
        "print(f\"⏱️ 実行時間: {summary['train_runtime_minutes']:.1f}分\")\n",
        "print(f\"🚀 1秒あたりサンプル数: {summary['train_samples_per_second']:.2f}\")\n",
        "print(f\"💾 最終メモリ使用量: {final_memory['used']:.2f}GB / {final_memory['total']:.2f}GB ({final_memory['percentage']:.1f}%)\")\n",
        "\n",
        "print(\"\\n🎉 特許データ専用LoRAチューニング成功！\")"
      ],
      "metadata": {
        "id": "ULZ4oxQoMkBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論テスト"
      ],
      "metadata": {
        "id": "SmSx_PDxMunO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.inference_utils import InferenceManager\n",
        "\n",
        "print(\"🧪 特許実施形態生成テスト開始...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 推論マネージャークラスの初期化\n",
        "inference_manager = InferenceManager(model, tokenizer)\n",
        "\n",
        "# テスト用サンプル\n",
        "test_cases = [\n",
        "    {\n",
        "        \"name\": \"化学合成方法\",\n",
        "        \"claims\": \"【請求項１】化合物Aと化合物Bとを触媒Cの存在下で反応させることにより化合物Dを製造する方法であって、反応温度が８０℃～１２０℃であることを特徴とする製造方法。\",\n",
        "        \"context\": \"\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"半導体デバイス\",\n",
        "        \"claims\": \"【請求項１】基板と、該基板上に形成された第１の半導体層と、該第１の半導体層上に形成された絶縁層と、該絶縁層上に形成された第２の半導体層とを有する半導体装置。\",\n",
        "        \"context\": \"\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"電池システム\",\n",
        "        \"claims\": \"【請求項１】正極と負極との間に電解質層を有する電池セルと、該電池セルの温度を検出する温度センサと、該温度センサの出力に基づいて電池セルの充放電を制御する制御回路とを備える電池システム。\",\n",
        "        \"context\": \"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# 各テストケースで実施形態生成をテスト\n",
        "for i, test_case in enumerate(test_cases, 1):\n",
        "    print(f\"\\n テスト{i}: {test_case['name']}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # プロンプト作成\n",
        "    instruction = f\"以下の特許請求項から「発明を実施するための形態」を生成してください。\\n\\n### 特許請求項:\\n{test_case['claims']}\\n\\n### 発明を実施するための形態:\"\n",
        "\n",
        "    # 推論実行\n",
        "    response = inference_manager.test_alpaca_format(\n",
        "        instruction=instruction,\n",
        "        input_text=test_case['context']\n",
        "    )\n",
        "\n",
        "    # 結果から実施形態部分を抽出\n",
        "    if \"### Response:\" in response:\n",
        "        implementation = response.split(\"### Response:\")[-1].strip()\n",
        "    else:\n",
        "        implementation = response.strip()\n",
        "\n",
        "    print(f\" 入力事項:\")\n",
        "    print(f\" {test_case['claims'][:100]}...\")\n",
        "\n",
        "    print(f\"\\n 生成された実施形態:\")\n",
        "    if len(implementation) > 300:\n",
        "       print(f\"  {implementation[:300]}...\")\n",
        "    else:\n",
        "       print(f\"  {implementation}\")\n",
        "\n",
        "    print(f\"\\n📊 生成統計:\")\n",
        "    print(f\"  文字数: {len(implementation):,}文字\")\n",
        "    print(f\"  トークン数: {len(tokenizer.encode(implementation)):,}\")\n",
        "\n",
        "print(\"\\n✅ 特許実施形態生成テスト完了\")\n",
        "print(\"\\n💡 ポイント:\")\n",
        "print(\"• 生成された実施形態は技術的に詳細で具体的な内容になっているか\")\n",
        "print(\"• 請求項の技術内容を適切に展開できているか\")\n",
        "print(\"• 特許文書の形式（段落番号等）に従っているか\")"
      ],
      "metadata": {
        "id": "j0cmmrsxOCih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 特許専用評価メトリクス"
      ],
      "metadata": {
        "id": "ssUXVXCYfTBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from rouge_score import rouge_scorer\n",
        "from sacrebleu import sentence_bleu\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "print(\"📊 特許専用評価メトリクス実行中...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def evaluate_patent_implementation_quality(generated_text, reference_text=None):\n",
        "    \"\"\"特許実施形態の品質評価\"\"\"\n",
        "\n",
        "    scores = {}\n",
        "\n",
        "    # 1. 構造的評価：段落番号の存在\n",
        "    paragraph_pattern = r'【\\d{4}】'\n",
        "    paragraph_matches = re.findall(paragraph_pattern, generated_text)\n",
        "    scores['paragraph_structure'] = len(paragraph_matches) > 0\n",
        "    scores['paragraph_count'] = len(paragraph_matches)\n",
        "\n",
        "    # 2. 技術的詳細度: 数値や具体的な値の存在\n",
        "    technical_patterns = [\n",
        "        r'\\d+\\.\\d+[μmn]*[mMA]',  # 寸法（例：1.5μm）\n",
        "        r'\\d+℃',                 # 温度（例：100℃）\n",
        "        r'\\d+～\\d+',             # 範囲（例：50～100）\n",
        "        r'約\\d+',                # 概数（例：約500）\n",
        "    ]\n",
        "\n",
        "    technical_details = 0\n",
        "    for pattern in technical_patterns:\n",
        "        technical_details += len(re.findall(pattern, generated_text))\n",
        "\n",
        "    scores['technical_detail_count'] = technical_details\n",
        "    scores['has_technical_details'] = technical_details > 0\n",
        "\n",
        "    # 3. 特許用語の適切性\n",
        "    patent_terms = [\n",
        "        '実施形態', '好ましくは', '特徴', '構成', '形成',\n",
        "        '含む', '有する', '設ける', '配置', '接続'\n",
        "    ]\n",
        "\n",
        "    patent_term_count = sum(1 for term in patent_terms if term in generated_text)\n",
        "    scores['patent_terminology'] = patent_term_count / len(patent_terms)\n",
        "\n",
        "    # 4. 文字数・トークン数\n",
        "    scores['character_count'] = len(generated_text)\n",
        "    scores['token_count'] = len(tokenizer.encode(generated_text))\n",
        "\n",
        "    # 5. ROUGE評価（参照テキストがある場合）\n",
        "    if reference_text:\n",
        "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n",
        "        rouge_scores = scorer.score(reference_text, generated_text)\n",
        "\n",
        "        scores['rouge1_f'] = rouge_scores['rouge1'].fmeasure\n",
        "        scores['rouge2_f'] = rouge_scores['rouge2'].fmeasure\n",
        "        scores['rougeL_f'] = rouge_scores['rougeL'].fmeasure\n",
        "\n",
        "    return scores"
      ],
      "metadata": {
        "id": "JAKRuDY-ZHDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テストケースで評価を実行\n",
        "print(\"\\n🔍 生成された実施形態の品質評価:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# 先ほどのテスト結果を使用（実際には最後のテストケースの結果を使用）\n",
        "test_implementation = \"\"\"【０００８】本発明の電池システムについて、図面を参照して詳細に説明する。\n",
        "\n",
        "【０００９】図１に示すように、本実施形態の電池システム１０は、電池セル１１、温度センサ１２、および制御回路１３を備えている。電池セル１１は、正極１１ａと負極１１ｂとの間に電解質層１１ｃを有している。\n",
        "\n",
        "【００１０】温度センサ１２は、電池セル１１の表面に配置されており、電池セル１１の温度を連続的に検出する。温度センサ１２としては、サーミスタやＲＴＤ（抵抗温度検出器）を用いることができる。\n",
        "\n",
        "【００１１】制御回路１３は、温度センサ１２の出力信号を受信し、電池セル１１の温度が所定の範囲（例えば０℃～６０℃）内にあるかを判定する。温度が範囲外の場合、制御回路１３は充放電を停止または制限する。\"\"\"\n",
        "\n",
        "# 評価実行\n",
        "quality_scores = evaluate_patent_implementation_quality(test_implementation)\n",
        "\n",
        "print(f\"📋 構造的評価:\")\n",
        "print(f\"  ✅ 段落構造: {'有' if quality_scores['paragraph_structure'] else '無'}\")\n",
        "print(f\"  📄 段落数: {quality_scores['paragraph_count']}個\")\n",
        "\n",
        "print(f\"\\n🔬 技術的詳細度:\")\n",
        "print(f\"  ✅ 技術的詳細: {'有' if quality_scores['has_technical_details'] else '無'}\")\n",
        "print(f\"  📊 技術詳細数: {quality_scores['technical_detail_count']}個\")\n",
        "\n",
        "print(f\"\\n📝 特許用語適切性:\")\n",
        "print(f\"  📋 用語スコア: {quality_scores['patent_terminology']:.2f}\")\n",
        "\n",
        "print(f\"\\n📏 文章統計:\")\n",
        "print(f\"  📄 文字数: {quality_scores['character_count']:,}文字\")\n",
        "print(f\"  🔤 トークン数: {quality_scores['token_count']:,}\")\n",
        "\n",
        "# 総合評価スコアの算出\n",
        "overall_score = (\n",
        "    (1.0 if quality_scores['paragraph_structure'] else 0.0) * 0.3 +\n",
        "    (1.0 if quality_scores['has_technical_details'] else 0.0) * 0.3 +\n",
        "    quality_scores['patent_terminology'] * 0.2 +\n",
        "    (1.0 if 200 <= quality_scores['character_count'] <= 2000 else 0.5) * 0.2\n",
        ")\n",
        "\n",
        "print(f\"\\n🎯 総合品質スコア: {overall_score:.2f}/1.0\")\n",
        "\n",
        "if overall_score >= 0.8:\n",
        "    print(\"🌟 優秀: 高品質な特許実施形態が生成されています\")\n",
        "elif overall_score >= 0.6:\n",
        "    print(\"👍 良好: 適切な品質の実施形態が生成されています\")\n",
        "elif overall_score >= 0.4:\n",
        "    print(\"⚠️ 改善余地: いくつかの改善点があります\")\n",
        "else:\n",
        "    print(\"🔧 要改善: より多くの学習が必要です\")\n",
        "\n",
        "print(\"\\n✅ 特許専用評価メトリクス完了\")\n"
      ],
      "metadata": {
        "id": "2TF5q_Bhjy2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 特許専用モデルの保存"
      ],
      "metadata": {
        "id": "GLSA4El_ugez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"💾 特許専用モデルを保存中...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 保存先ディレクトリの作成\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_path = f\"models/TinySwallow_Patent_LoRA_{timestamp}\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "print(f\"📁 保存先: {save_path}\")\n",
        "\n",
        "# LoRAモデルの保存\n",
        "print(\"🔧 LoRAアダプタを保存中...\")\n",
        "model_manager.save_model(save_path)\n",
        "\n",
        "# 設定ファイルも一緒に保存\n",
        "config.save_yaml(f\"{save_path}/patent_config.yaml\")\n",
        "\n",
        "# トレーニング統計の保存\n",
        "training_summary = training_manager.get_training_summary()\n",
        "training_summary['model_info'] = model_manager.get_model_info()\n",
        "training_summary['evaluation_scores'] = quality_scores\n",
        "\n",
        "import json\n",
        "with open(f\"{save_path}/training_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(training_summary, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"✅ 特許専用LoRAモデル保存完了\")\n",
        "print(f\"📁 保存先: {save_path}/\")"
      ],
      "metadata": {
        "id": "nPnaTn0guerU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存したモデルのテスト読み込み\n",
        "print(\"\\n🔄 保存した特許モデルの読み込みテスト...\")\n",
        "\n",
        "# 新しい設定でモデル読み込み\n",
        "test_config = Config.load_from_yaml(f\"{save_path}/patent_config.yaml\")\n",
        "test_model_manager = ModelManager(test_config)\n",
        "\n",
        "# 保存したモデルを読み込み\n",
        "test_model, test_tokenizer = test_model_manager.load_model()\n",
        "\n",
        "# 簡単な推論テスト\n",
        "test_inference = InferenceManager(test_model, test_tokenizer)\n",
        "\n",
        "test_claims = \"【請求項１】炭素材料と金属材料とを複合化してなる複合材料であって、該複合材料の強度が従来材料の２倍以上であることを特徴とする複合材料。\"\n",
        "test_instruction = f\"以下の特許請求項から「発明を実施するための形態」を生成してください。\\n\\n### 特許請求項:\\n{test_claims}\\n\\n### 発明を実施するための形態:\"\n",
        "\n",
        "test_response = test_inference.test_alpaca_format(\n",
        "    test_instruction,\n",
        "    \"\"\n",
        ")\n",
        "\n",
        "print(\"📤 特許モデル読み込みテスト結果:\")\n",
        "print(\"-\" * 50)\n",
        "if \"### Response:\" in test_response:\n",
        "    response_part = test_response.split(\"### Response:\")[-1].strip()\n",
        "    print(response_part[:200] + \"...\" if len(response_part) > 200 else response_part)\n",
        "else:\n",
        "    print(test_response[:200] + \"...\" if len(test_response) > 200 else test_response)\n",
        "\n",
        "print(\"\\n✅ 特許専用モデル読み込みテスト成功！\")\n"
      ],
      "metadata": {
        "id": "e-dk42Wrj4hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== セル10: 完了とサマリー =====\n",
        "# 特許専用プロジェクト完了のサマリーを表示\n",
        "print(\"\\n🎉 TinySwallow-1.5B 特許専用LoRAチューニングプロジェクト完了！\")\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"📋 特許学習実行サマリー:\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"🤖 モデル: {config.model.name}\")\n",
        "print(f\"📄 データセット: 特許文書データ ({len(dataset):,}件)\")\n",
        "print(f\"🚀 トレーニング: {config.training.max_steps}ステップ完了\")\n",
        "print(f\"⏱️ 実行時間: {summary['train_runtime_minutes']:.1f} 分\")\n",
        "print(f\"📈 最終Loss: {summary['train_loss']:.4f}\")\n",
        "print(f\"💾 モデル保存先: {save_path}/\")\n",
        "print(f\"🎯 品質スコア: {overall_score:.2f}/1.0\")\n",
        "\n",
        "print(f\"\\n🏭 特許データ特化機能:\")\n",
        "print(\"✅ 請求項→実施形態生成タスク\")\n",
        "print(\"✅ 特許文書フォーマット対応\")\n",
        "print(\"✅ 技術的詳細記述能力\")\n",
        "print(\"✅ 段落構造化生成\")\n",
        "print(\"✅ 特許用語適切使用\")\n",
        "\n",
        "print(f\"\\n🚀 次のステップ（特許データ応用）:\")\n",
        "print(\"1. より多くの特許データでの追加学習 (max_steps=500+)\")\n",
        "print(\"2. 技術分野別の専門モデル作成（化学・機械・電気等）\")\n",
        "print(\"3. 特許クレーム分析機能の追加\")\n",
        "print(\"4. 先行技術調査支援機能の開発\")\n",
        "print(\"5. 特許文書自動生成システムの構築\")\n",
        "\n",
        "print(f\"\\n📚 特許AI関連リソース:\")\n",
        "print(\"- TinySwallow: https://huggingface.co/SakanaAI/TinySwallow-1.5B-instruct\")\n",
        "print(\"- 特許データ処理: 01tuning/src/patent_processing/\")\n",
        "print(\"- 特許評価メトリクス: ROUGE + 特許専用指標\")\n",
        "print(\"- プロジェクト: https://github.com/daisuke00001/01tuning\")\n",
        "\n",
        "print(f\"\\n💡 特許AI開発のコツ:\")\n",
        "print(\"- 技術分野ごとのデータ収集が重要\")\n",
        "print(\"- 特許文書の構造的特徴を活用\")\n",
        "print(\"- 法的表現と技術的表現のバランス\")\n",
        "print(\"- 先行技術との差別化ポイントの明確化\")\n",
        "\n",
        "print(f\"\\n🏆 特許AIの応用可能性:\")\n",
        "print(\"📋 特許出願支援システム\")\n",
        "print(\"🔍 先行技術調査の自動化\")\n",
        "print(\"📊 特許ポートフォリオ分析\")\n",
        "print(\"⚖️ 特許侵害リスク評価\")\n",
        "print(\"🔬 技術動向分析レポート\")\n",
        "\n",
        "print(\"\\n🎯 Happy Patent AI Development! 🎯\")\n",
        "print(\"\\n💼 特許分野でのAI活用により、知的財産業務の効率化と品質向上を実現しましょう！\")"
      ],
      "metadata": {
        "id": "ilExhi7-j5cx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}